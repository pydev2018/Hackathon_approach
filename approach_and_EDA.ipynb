{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd0138a559277120b3f41362cbeeda196e91ebce770d8c31e460f13b39a435365c6",
   "display_name": "Python 3.6.13 64-bit ('joathon': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "sns.set(style=\"ticks\", context=\"talk\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For EDA\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from train, test and submission csv files\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "source": [
    "## Data cleaning and imputation "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for duplicates \n",
    "def remove_duplicate(data):\n",
    "    data.drop_duplicates(keep=\"first\", inplace=True)\n",
    "    return \"Checked Duplicates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Checked Duplicates'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "remove_duplicate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to Impute missing values with a new dummy variable , this is done to preserve as much information as possible\n",
    "def impute_nan_create_category(DataFrame,ColName):\n",
    "     DataFrame[ColName] = np.where(DataFrame[ColName].isnull(),\"Unknown\",DataFrame[ColName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply on train \n",
    "for Columns in ['Credit_Product']:\n",
    "    impute_nan_create_category(train,Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply on test \n",
    "for Columns in ['Credit_Product']:\n",
    "    impute_nan_create_category(test,Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display information about dataframe\n",
    "data_types = [\"float32\",\"float64\",\"int32\",\"int64\",\"object\",\"category\",\"datetime64[ns]\"]\n",
    "def display_data_information(data, data_types):\n",
    "    data.info()\n",
    "    print(\"\\n\")\n",
    "    for VARIABLE in data_types :\n",
    "        data_types = data.select_dtypes(include=[ VARIABLE ]).dtypes\n",
    "    if len(data_types) > 0 :\n",
    "        print(str(len(data_types))+\" \"+VARIABLE+\" Features\\n\"+str(data_types)+\"\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 245725 entries, 0 to 245724\nData columns (total 11 columns):\n #   Column               Non-Null Count   Dtype \n---  ------               --------------   ----- \n 0   ID                   245725 non-null  object\n 1   Gender               245725 non-null  object\n 2   Age                  245725 non-null  int64 \n 3   Region_Code          245725 non-null  object\n 4   Occupation           245725 non-null  object\n 5   Channel_Code         245725 non-null  object\n 6   Vintage              245725 non-null  int64 \n 7   Credit_Product       245725 non-null  object\n 8   Avg_Account_Balance  245725 non-null  int64 \n 9   Is_Active            245725 non-null  object\n 10  Is_Lead              245725 non-null  int64 \ndtypes: int64(4), object(7)\nmemory usage: 22.5+ MB\n\n\n"
     ]
    }
   ],
   "source": [
    "# Display info about train\n",
    "display_data_information(train, data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 105312 entries, 0 to 105311\nData columns (total 10 columns):\n #   Column               Non-Null Count   Dtype \n---  ------               --------------   ----- \n 0   ID                   105312 non-null  object\n 1   Gender               105312 non-null  object\n 2   Age                  105312 non-null  int64 \n 3   Region_Code          105312 non-null  object\n 4   Occupation           105312 non-null  object\n 5   Channel_Code         105312 non-null  object\n 6   Vintage              105312 non-null  int64 \n 7   Credit_Product       105312 non-null  object\n 8   Avg_Account_Balance  105312 non-null  int64 \n 9   Is_Active            105312 non-null  object\ndtypes: int64(3), object(7)\nmemory usage: 8.0+ MB\n\n\n"
     ]
    }
   ],
   "source": [
    "# Display info about test\n",
    "display_data_information(test, data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the ID column \n",
    "\n",
    "train = train.drop('ID', axis=1)\n",
    "test = test.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Gender  Age Region_Code     Occupation Channel_Code  Vintage  \\\n",
       "0  Female   73       RG268          Other           X3       43   \n",
       "1  Female   30       RG277       Salaried           X1       32   \n",
       "2  Female   56       RG268  Self_Employed           X3       26   \n",
       "3    Male   34       RG270       Salaried           X1       19   \n",
       "4  Female   30       RG282       Salaried           X1       33   \n",
       "\n",
       "  Credit_Product  Avg_Account_Balance Is_Active  Is_Lead  \n",
       "0             No              1045696        No        0  \n",
       "1             No               581988        No        0  \n",
       "2             No              1484315       Yes        0  \n",
       "3             No               470454        No        0  \n",
       "4             No               886787        No        0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Region_Code</th>\n      <th>Occupation</th>\n      <th>Channel_Code</th>\n      <th>Vintage</th>\n      <th>Credit_Product</th>\n      <th>Avg_Account_Balance</th>\n      <th>Is_Active</th>\n      <th>Is_Lead</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Female</td>\n      <td>73</td>\n      <td>RG268</td>\n      <td>Other</td>\n      <td>X3</td>\n      <td>43</td>\n      <td>No</td>\n      <td>1045696</td>\n      <td>No</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Female</td>\n      <td>30</td>\n      <td>RG277</td>\n      <td>Salaried</td>\n      <td>X1</td>\n      <td>32</td>\n      <td>No</td>\n      <td>581988</td>\n      <td>No</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Female</td>\n      <td>56</td>\n      <td>RG268</td>\n      <td>Self_Employed</td>\n      <td>X3</td>\n      <td>26</td>\n      <td>No</td>\n      <td>1484315</td>\n      <td>Yes</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Male</td>\n      <td>34</td>\n      <td>RG270</td>\n      <td>Salaried</td>\n      <td>X1</td>\n      <td>19</td>\n      <td>No</td>\n      <td>470454</td>\n      <td>No</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Female</td>\n      <td>30</td>\n      <td>RG282</td>\n      <td>Salaried</td>\n      <td>X1</td>\n      <td>33</td>\n      <td>No</td>\n      <td>886787</td>\n      <td>No</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Gender  Age Region_Code Occupation Channel_Code  Vintage Credit_Product  \\\n",
       "0    Male   29       RG254      Other           X1       25            Yes   \n",
       "1    Male   43       RG268      Other           X2       49        Unknown   \n",
       "2    Male   31       RG270   Salaried           X1       14             No   \n",
       "3    Male   29       RG272      Other           X1       33             No   \n",
       "4  Female   29       RG270      Other           X1       19             No   \n",
       "\n",
       "   Avg_Account_Balance Is_Active  \n",
       "0               742366        No  \n",
       "1               925537        No  \n",
       "2               215949        No  \n",
       "3               868070        No  \n",
       "4               657087        No  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Region_Code</th>\n      <th>Occupation</th>\n      <th>Channel_Code</th>\n      <th>Vintage</th>\n      <th>Credit_Product</th>\n      <th>Avg_Account_Balance</th>\n      <th>Is_Active</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Male</td>\n      <td>29</td>\n      <td>RG254</td>\n      <td>Other</td>\n      <td>X1</td>\n      <td>25</td>\n      <td>Yes</td>\n      <td>742366</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>43</td>\n      <td>RG268</td>\n      <td>Other</td>\n      <td>X2</td>\n      <td>49</td>\n      <td>Unknown</td>\n      <td>925537</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Male</td>\n      <td>31</td>\n      <td>RG270</td>\n      <td>Salaried</td>\n      <td>X1</td>\n      <td>14</td>\n      <td>No</td>\n      <td>215949</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Male</td>\n      <td>29</td>\n      <td>RG272</td>\n      <td>Other</td>\n      <td>X1</td>\n      <td>33</td>\n      <td>No</td>\n      <td>868070</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Female</td>\n      <td>29</td>\n      <td>RG270</td>\n      <td>Other</td>\n      <td>X1</td>\n      <td>19</td>\n      <td>No</td>\n      <td>657087</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "source": [
    "## EDA Part "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### EDA using logistic regression \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eda = train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eda = train_eda.drop('Is_Lead', axis=1)\n",
    "y_eda = train_eda[['Is_Lead']]\n",
    "X_eda = pd.get_dummies(X_eda, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eda, X_test_eda, y_train_eda, y_test_eda = train_test_split(X_eda, y_eda, test_size=0.25)"
   ]
  },
  {
   "source": [
    "### Build the logistic regression model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimization terminated successfully.\n         Current function value: 0.366902\n         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "logit = sm.Logit(y_train_eda, sm.add_constant(X_train_eda))\n",
    "lg = logit.fit()"
   ]
  },
  {
   "source": [
    "### Check the summary of the model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                Is_Lead   No. Observations:               184293\nModel:                          Logit   Df Residuals:                   184245\nMethod:                           MLE   Df Model:                           47\nDate:                Mon, 31 May 2021   Pseudo R-squ.:                  0.3318\nTime:                        18:51:10   Log-Likelihood:                -67618.\nconverged:                       True   LL-Null:                   -1.0119e+05\nCovariance Type:            nonrobust   LLR p-value:                     0.000\n============================================================================================\n                               coef    std err          z      P>|z|      [0.025      0.975]\n--------------------------------------------------------------------------------------------\nconst                       -3.7089      0.100    -36.971      0.000      -3.906      -3.512\nAge                          0.0084      0.001     10.796      0.000       0.007       0.010\nVintage                      0.0088      0.000     31.290      0.000       0.008       0.009\nAvg_Account_Balance      -2.446e-08   8.69e-09     -2.815      0.005   -4.15e-08   -7.43e-09\nGender_Male                  0.0323      0.014      2.253      0.024       0.004       0.060\nRegion_Code_RG251            0.2442      0.089      2.734      0.006       0.069       0.419\nRegion_Code_RG252            0.2141      0.099      2.153      0.031       0.019       0.409\nRegion_Code_RG253            0.1626      0.109      1.486      0.137      -0.052       0.377\nRegion_Code_RG254            0.1228      0.081      1.525      0.127      -0.035       0.281\nRegion_Code_RG255            0.3575      0.107      3.330      0.001       0.147       0.568\nRegion_Code_RG256            0.0624      0.110      0.568      0.570      -0.153       0.278\nRegion_Code_RG257            0.2580      0.091      2.842      0.004       0.080       0.436\nRegion_Code_RG258            0.2081      0.112      1.854      0.064      -0.012       0.428\nRegion_Code_RG259            0.1471      0.105      1.405      0.160      -0.058       0.352\nRegion_Code_RG260            0.1751      0.103      1.701      0.089      -0.027       0.377\nRegion_Code_RG261            0.1754      0.088      1.984      0.047       0.002       0.349\nRegion_Code_RG262            0.0917      0.117      0.784      0.433      -0.138       0.321\nRegion_Code_RG263            0.3505      0.096      3.633      0.000       0.161       0.540\nRegion_Code_RG264            0.1155      0.109      1.062      0.288      -0.098       0.329\nRegion_Code_RG265            0.2016      0.114      1.767      0.077      -0.022       0.425\nRegion_Code_RG266            0.0544      0.127      0.427      0.669      -0.195       0.304\nRegion_Code_RG267           -0.1788      0.129     -1.391      0.164      -0.431       0.073\nRegion_Code_RG268            0.2290      0.079      2.881      0.004       0.073       0.385\nRegion_Code_RG269            0.3305      0.087      3.787      0.000       0.159       0.502\nRegion_Code_RG270            0.2162      0.090      2.412      0.016       0.041       0.392\nRegion_Code_RG271            0.1022      0.122      0.839      0.401      -0.137       0.341\nRegion_Code_RG272            0.1856      0.092      2.024      0.043       0.006       0.365\nRegion_Code_RG273            0.2734      0.093      2.941      0.003       0.091       0.456\nRegion_Code_RG274            0.0935      0.093      1.007      0.314      -0.088       0.275\nRegion_Code_RG275            0.0144      0.101      0.142      0.887      -0.184       0.213\nRegion_Code_RG276            0.2139      0.099      2.152      0.031       0.019       0.409\nRegion_Code_RG277            0.3079      0.083      3.696      0.000       0.145       0.471\nRegion_Code_RG278            0.0054      0.113      0.048      0.962      -0.217       0.228\nRegion_Code_RG279            0.3038      0.095      3.208      0.001       0.118       0.489\nRegion_Code_RG280            0.2566      0.083      3.087      0.002       0.094       0.419\nRegion_Code_RG281            0.1440      0.092      1.571      0.116      -0.036       0.324\nRegion_Code_RG282            0.1502      0.092      1.640      0.101      -0.029       0.330\nRegion_Code_RG283            0.2184      0.080      2.735      0.006       0.062       0.375\nRegion_Code_RG284            0.2376      0.081      2.934      0.003       0.079       0.396\nOccupation_Other            -0.7906      0.056    -14.061      0.000      -0.901      -0.680\nOccupation_Salaried          0.1827      0.058      3.145      0.002       0.069       0.297\nOccupation_Self_Employed    -0.7013      0.055    -12.806      0.000      -0.809      -0.594\nChannel_Code_X2              0.9505      0.025     38.135      0.000       0.902       0.999\nChannel_Code_X3              0.8146      0.026     30.826      0.000       0.763       0.866\nChannel_Code_X4              0.8590      0.047     18.207      0.000       0.767       0.952\nCredit_Product_Unknown       3.9906      0.023    171.615      0.000       3.945       4.036\nCredit_Product_Yes           1.6083      0.016    100.684      0.000       1.577       1.640\nIs_Active_Yes                0.3311      0.015     22.153      0.000       0.302       0.360\n============================================================================================\n"
     ]
    }
   ],
   "source": [
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "print(lg.summary())"
   ]
  },
  {
   "source": [
    "### The pseudo r-square shows that only 33% of the entire variation in the data is explained by the model. It is really not a good model!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### We will calculate the odds ratio from the coefficients using the formula odds ratio=exp(coef). Next we will calculate the probability from the odds ratio using the formula probability = odds / (1+odds) and filter by decending odds ratio "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_coef = pd.DataFrame(lg.params, columns=['coef'])\n",
    "log_coef.loc[:, \"Odds_ratio\"] = np.exp(log_coef.coef)\n",
    "log_coef['probability'] = log_coef['Odds_ratio']/(1+log_coef['Odds_ratio'])\n",
    "log_coef['pval']=lg.pvalues\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          coef  Odds_ratio  probability  pval\n",
       "Credit_Product_Unknown    3.99       54.09         0.98  0.00\n",
       "Credit_Product_Yes        1.61        4.99         0.83  0.00\n",
       "Channel_Code_X2           0.95        2.59         0.72  0.00\n",
       "Channel_Code_X4           0.86        2.36         0.70  0.00\n",
       "Channel_Code_X3           0.81        2.26         0.69  0.00\n",
       "Region_Code_RG255         0.36        1.43         0.59  0.00\n",
       "Region_Code_RG263         0.35        1.42         0.59  0.00\n",
       "Is_Active_Yes             0.33        1.39         0.58  0.00\n",
       "Region_Code_RG269         0.33        1.39         0.58  0.00\n",
       "Region_Code_RG277         0.31        1.36         0.58  0.00\n",
       "Region_Code_RG279         0.30        1.35         0.58  0.00\n",
       "Region_Code_RG273         0.27        1.31         0.57  0.00\n",
       "Region_Code_RG257         0.26        1.29         0.56  0.00\n",
       "Region_Code_RG280         0.26        1.29         0.56  0.00\n",
       "Region_Code_RG251         0.24        1.28         0.56  0.01\n",
       "Region_Code_RG284         0.24        1.27         0.56  0.00\n",
       "Region_Code_RG268         0.23        1.26         0.56  0.00\n",
       "Region_Code_RG283         0.22        1.24         0.55  0.01\n",
       "Region_Code_RG270         0.22        1.24         0.55  0.02\n",
       "Region_Code_RG252         0.21        1.24         0.55  0.03\n",
       "Region_Code_RG276         0.21        1.24         0.55  0.03\n",
       "Region_Code_RG258         0.21        1.23         0.55  0.06\n",
       "Region_Code_RG265         0.20        1.22         0.55  0.08\n",
       "Region_Code_RG272         0.19        1.20         0.55  0.04\n",
       "Occupation_Salaried       0.18        1.20         0.55  0.00\n",
       "Region_Code_RG261         0.18        1.19         0.54  0.05\n",
       "Region_Code_RG260         0.18        1.19         0.54  0.09\n",
       "Gender_Male               0.03        1.03         0.51  0.02\n",
       "Vintage                   0.01        1.01         0.50  0.00\n",
       "Age                       0.01        1.01         0.50  0.00\n",
       "Avg_Account_Balance      -0.00        1.00         0.50  0.00\n",
       "Occupation_Self_Employed -0.70        0.50         0.33  0.00\n",
       "Occupation_Other         -0.79        0.45         0.31  0.00\n",
       "const                    -3.71        0.02         0.02  0.00"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>coef</th>\n      <th>Odds_ratio</th>\n      <th>probability</th>\n      <th>pval</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Credit_Product_Unknown</th>\n      <td>3.99</td>\n      <td>54.09</td>\n      <td>0.98</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Credit_Product_Yes</th>\n      <td>1.61</td>\n      <td>4.99</td>\n      <td>0.83</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Channel_Code_X2</th>\n      <td>0.95</td>\n      <td>2.59</td>\n      <td>0.72</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Channel_Code_X4</th>\n      <td>0.86</td>\n      <td>2.36</td>\n      <td>0.70</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Channel_Code_X3</th>\n      <td>0.81</td>\n      <td>2.26</td>\n      <td>0.69</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG255</th>\n      <td>0.36</td>\n      <td>1.43</td>\n      <td>0.59</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG263</th>\n      <td>0.35</td>\n      <td>1.42</td>\n      <td>0.59</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Is_Active_Yes</th>\n      <td>0.33</td>\n      <td>1.39</td>\n      <td>0.58</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG269</th>\n      <td>0.33</td>\n      <td>1.39</td>\n      <td>0.58</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG277</th>\n      <td>0.31</td>\n      <td>1.36</td>\n      <td>0.58</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG279</th>\n      <td>0.30</td>\n      <td>1.35</td>\n      <td>0.58</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG273</th>\n      <td>0.27</td>\n      <td>1.31</td>\n      <td>0.57</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG257</th>\n      <td>0.26</td>\n      <td>1.29</td>\n      <td>0.56</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG280</th>\n      <td>0.26</td>\n      <td>1.29</td>\n      <td>0.56</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG251</th>\n      <td>0.24</td>\n      <td>1.28</td>\n      <td>0.56</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG284</th>\n      <td>0.24</td>\n      <td>1.27</td>\n      <td>0.56</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG268</th>\n      <td>0.23</td>\n      <td>1.26</td>\n      <td>0.56</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG283</th>\n      <td>0.22</td>\n      <td>1.24</td>\n      <td>0.55</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG270</th>\n      <td>0.22</td>\n      <td>1.24</td>\n      <td>0.55</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG252</th>\n      <td>0.21</td>\n      <td>1.24</td>\n      <td>0.55</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG276</th>\n      <td>0.21</td>\n      <td>1.24</td>\n      <td>0.55</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG258</th>\n      <td>0.21</td>\n      <td>1.23</td>\n      <td>0.55</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG265</th>\n      <td>0.20</td>\n      <td>1.22</td>\n      <td>0.55</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG272</th>\n      <td>0.19</td>\n      <td>1.20</td>\n      <td>0.55</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>Occupation_Salaried</th>\n      <td>0.18</td>\n      <td>1.20</td>\n      <td>0.55</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG261</th>\n      <td>0.18</td>\n      <td>1.19</td>\n      <td>0.54</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>Region_Code_RG260</th>\n      <td>0.18</td>\n      <td>1.19</td>\n      <td>0.54</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>Gender_Male</th>\n      <td>0.03</td>\n      <td>1.03</td>\n      <td>0.51</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>Vintage</th>\n      <td>0.01</td>\n      <td>1.01</td>\n      <td>0.50</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>0.01</td>\n      <td>1.01</td>\n      <td>0.50</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Avg_Account_Balance</th>\n      <td>-0.00</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Occupation_Self_Employed</th>\n      <td>-0.70</td>\n      <td>0.50</td>\n      <td>0.33</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>Occupation_Other</th>\n      <td>-0.79</td>\n      <td>0.45</td>\n      <td>0.31</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>const</th>\n      <td>-3.71</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "log_coef = log_coef.sort_values(by=\"Odds_ratio\", ascending=False)\n",
    "pval_filter = log_coef['pval']<=0.1\n",
    "log_coef[pval_filter]"
   ]
  },
  {
   "source": [
    "If we analyze the data, we can see that the customers who have unknown credit product  have a 98% probability of becoming the lead while the ones having yes have 83% probability of becoming a lead.\n",
    "\n",
    "Similarly, the customers in channel code X2 have odds of 2.59 to become a lead as compared to others , this empasise the importance of credit product. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Visual EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Is_Lead'] = le.fit_transform(train['Is_Lead'])\n",
    "#train['Is_Active'] = le.fit_transform(train['Is_Lead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Is_Lead'].value_counts().plot.pie(autopct = '%1.1f%%',colors=['Orange','Blue'], figsize = (4,4))"
   ]
  },
  {
   "source": [
    "### Data is Imbalanced. Only 23.7% of customers are likely to become lead."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of target variable with respect to gender\n",
    "sns.countplot(train['Gender'], hue = train['Is_Lead'],palette=['Orange','Purple'])"
   ]
  },
  {
   "source": [
    "### There are more leads in male customers "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of Age\n",
    "f,ax = plt.subplots(nrows=2,ncols=1,figsize=(20,10))\n",
    "axx = ax.flatten()\n",
    "#plt.figure(figsize=(30,10))\n",
    "sns.distplot(train['Age'],ax=axx[0], color='Blue')\n",
    "sns.boxplot(train['Age'],ax=axx[1],color='Orange')"
   ]
  },
  {
   "source": [
    "### Most of the people are in age group of 30-55"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on this observation we divide age into bins\n",
    "age_grp_20_to_30 = train[ train['Age'] <31]\n",
    "age_grp_31_to_40 = train[ train['Age'].between(31,40)]\n",
    "age_grp_41_to_50 = train[ train['Age'].between(41,50)]\n",
    "age_grp_50_to_60 = train[ train['Age'].between(51,60)]\n",
    "age_grp_old = train[ train['Age'] >60]\n",
    "\n",
    "age_grp = [age_grp_20_to_30,age_grp_31_to_40,age_grp_41_to_50,age_grp_50_to_60,age_grp_old]\n",
    "age_grp_name = ['age_grp_20_to_30','age_grp_31_to_40','age_grp_41_to_50','age_grp_50_to_60','age_grp_old']\n",
    "age_grp_dict = dict(zip(age_grp_name, age_grp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of target variable with respect to age  \n",
    "f,ax = plt.subplots(nrows=2, ncols=3, figsize = (20,10))\n",
    "axx = ax.flatten()\n",
    "for pos,tup in enumerate(age_grp_dict.items()):\n",
    "    axx[pos].set_title(tup[0])\n",
    "    data = tup[1]\n",
    "    data['Is_Lead'].value_counts().plot.pie(autopct='%1.1f%%', ax = axx[pos],colors=['Red','Blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(nrows=2, ncols=3, figsize = (20,10))\n",
    "axx = ax.flatten()\n",
    "plt.title('Lead Percentage of Different Age Groups with Genders',fontsize=25,x=-0.5,y=2.5)\n",
    "for pos,tup in enumerate(age_grp_dict.items()):\n",
    "    axx[pos].set_title(tup[0])\n",
    "    temp = tup[1]\n",
    "    temp.groupby('Gender')['Is_Lead'].value_counts().plot.pie(autopct='%1.1f%%', ax = axx[pos],colors=['Orange','Purple'])"
   ]
  },
  {
   "source": [
    "### Age group 50-60 and 41-50 and age group old , males seem to be the dominant customers "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Credit_Product'].value_counts().plot.pie(autopct='%1.1f%%',colors = ['Blue','Red', 'Yellow'])"
   ]
  },
  {
   "source": [
    "### Distribution of credit product "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(nrows=1,ncols=3,figsize = (20,5))\n",
    "axx = ax.flatten()\n",
    "#plt.title('Driving_License wise Response',fontsize=40,x=-0.5,y=2)\n",
    "axx[0].set_title('Credit_Product = Yes')\n",
    "axx[1].set_title('Credit_Product = No')\n",
    "axx[2].set_title('Credit_Procuct = Unknown')\n",
    "train[ train['Credit_Product'] == 'Yes']['Is_Lead'].value_counts().plot.pie(autopct='%1.1f%%',colors = ['Blue','Red'],ax=axx[0])\n",
    "train[ train['Credit_Product'] == 'No']['Is_Lead'].value_counts().plot.pie(autopct='%1.1f%%',colors = ['Blue','Red'],ax=axx[1])\n",
    "train[ train['Credit_Product'] == 'Unknown']['Is_Lead'].value_counts().plot.pie(autopct='%1.1f%%',colors = ['Blue','Red'],ax=axx[2])"
   ]
  },
  {
   "source": [
    "###  This provides a revealing information that the missing credit product column contains 85.2% lead , dropping it would have been a mistake  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(nrows=1,ncols=2,figsize = (20,5))\n",
    "axx = ax.flatten()\n",
    "#plt.title('Driving_License wise Response',fontsize=40,x=-0.5,y=2)\n",
    "axx[0].set_title('Is_Active = Yes')\n",
    "axx[1].set_title('Is_Active = No')\n",
    "train[ train['Is_Active'] == 'Yes']['Is_Lead'].value_counts().plot.pie(autopct='%1.1f%%',colors = ['Blue','Red'],ax=axx[0])\n",
    "train[ train['Is_Active'] == 'No']['Is_Lead'].value_counts().plot.pie(autopct='%1.1f%%',colors = ['Blue','Red'],ax=axx[1])"
   ]
  },
  {
   "source": [
    "### Is_active is present in rough;y same manner in trget distribution \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (40,5))\n",
    "plt.title('Region Wise Response Count',fontsize=25)\n",
    "sns.countplot(train['Region_Code'], hue = train['Is_Lead'],palette=['Red','Blue'])"
   ]
  },
  {
   "source": [
    "### Region code 283 and 254, 284, 268 have highest number of customers "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_region = train['Region_Code'].unique()\n",
    "region_perc = {}\n",
    "for i in u_region:\n",
    "    total_region = train[ train['Region_Code'] == i].shape[0]\n",
    "    buy_region = train[ (train['Region_Code'] == i) & train['Is_Lead'] == 1].shape[0]\n",
    "    region_perc[i] = (buy_region/total_region)*100\n",
    "\n",
    "region_perc = sorted(region_perc.items(), key=lambda x: x[1], reverse=True)\n",
    "region_perc = list(zip(*region_perc))\n",
    "\n",
    "region = np.array(region_perc[0])\n",
    "region_perc = np.array(region_perc[1])\n",
    "region = pd.DataFrame(region)\n",
    "region_perc = pd.DataFrame(region_perc)\n",
    "\n",
    "region_res_perc = pd.concat((region,region_perc), axis=1)\n",
    "region_res_perc.columns = ['Region_Code', 'Buy_Percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,10))\n",
    "plt.title('Region Wise lead conversion  Percentage',fontsize=25)\n",
    "ax = sns.barplot(x = region_res_perc['Region_Code'], y = region_res_perc['Buy_Percentage'])"
   ]
  },
  {
   "source": [
    "### Which regions have highest lead  percentage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(train['Credit_Product'],hue=train['Is_Lead'],palette=['Brown','Purple'])"
   ]
  },
  {
   "source": [
    "### Importance of Credit_product variable is visible and the missing values contain a lot of leads "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "train['Occupation'].value_counts().plot.pie(autopct='%1.1f%%', colors = ['r', 'b', 'g', 'y'])"
   ]
  },
  {
   "source": [
    "### Distribution of Occupation "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,5))\n",
    "sns.countplot(train['Occupation'], hue = train['Is_Lead'])"
   ]
  },
  {
   "source": [
    "### Self Employed people have the most number of leads "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = train['Occupation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(nrows=1, ncols=4,figsize = (20,7))\n",
    "axx = ax.flatten()\n",
    "for pos,val in enumerate(ls):\n",
    "    axx[pos].set_title(str(val))\n",
    "    train[ train['Occupation'] == val]['Is_Lead'].value_counts().plot.pie(autopct = '%1.1f%%',ax = axx[pos], colors=['Purple', 'Orange'])"
   ]
  },
  {
   "source": [
    "### Entrepreneures have most leads whereas salaried the least "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train['Is_Active'], hue = train['Is_Lead'])"
   ]
  },
  {
   "source": [
    "### Number of leads is equally distributed in both active and not active "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(nrows=2,ncols=1,figsize=(20,7))\n",
    "axx = ax.flatten()\n",
    "#plt.figure(figsize=(30,10))\n",
    "sns.distplot(train['Avg_Account_Balance'],ax=axx[0], color='Blue')\n",
    "sns.boxplot(train['Avg_Account_Balance'],ax=axx[1],color='Orange')"
   ]
  },
  {
   "source": [
    "### Average account balance is highly skwed "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "sns.distplot(train[ train['Avg_Account_Balance'] < 100000]['Avg_Account_Balance'])#.plot.hist(bins = 500, frequency=(0,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "train['Channel_Code'].value_counts().plot.bar()"
   ]
  },
  {
   "source": [
    "### Channel code X4 has least values "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(nrows=2,ncols=1,figsize=(20,8))\n",
    "axx = ax.flatten()\n",
    "sns.distplot(train['Vintage'],ax=axx[0], color='Blue')\n",
    "sns.boxplot(train['Vintage'],ax=axx[1],color='Orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To combine and plot xcorr\n",
    "train_copy =  train \n",
    "test_copy = test \n",
    "train_copy['is_train'] = 1\n",
    "test_copy['is_train'] = 0\n",
    "test_copy['Is_Lead'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((train_copy,test_copy))\n",
    "#data.set_index('ID',inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('Age', data=data, orient='v', color='Red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('Avg_Account_Balance', data=data,orient='v', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(nrows=1,ncols=2,figsize = (20,7))\n",
    "axx = ax.flatten()\n",
    "sns.kdeplot(data['Avg_Account_Balance'], legend=False,ax = axx[0])\n",
    "sns.kdeplot(np.log(data['Avg_Account_Balance']), legend=False,ax = axx[1]) # after using log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_check = data.copy()\n",
    "\n",
    "col_ls = ['Gender', 'Occupation', 'Is_Active', 'Region_Code', 'Channel_Code', 'Credit_Product']\n",
    "\n",
    "for col in col_ls:\n",
    "    corr_check[col] = le.fit_transform(corr_check[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sns.heatmap(corr_check.corr(), annot=True, square=True,annot_kws={'size': 10})"
   ]
  },
  {
   "source": [
    "### Channel code and vintage are positively related "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Convert categorical columns , assign labels "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Gender']=train['Gender'].replace({'Male':1,'Female':0})\n",
    "train['Occupation']=train['Occupation'].replace({'Other':0,'Salaried':1,'Self_Employed':2, 'Entrepreneur':3})\n",
    "train['Occupation']=train['Occupation'].astype(int)\n",
    "train['Region_Code']=train['Region_Code'].replace({'RG268':0,'RG277':1,'RG270':2,'RG282':3,'RG261':4, 'RG265':5, 'RG283':6, 'RG254':7,\n",
    "                                                              'RG269':8, 'RG257':9, 'RG279':10, 'RG280':11, 'RG252':12, 'RG284':13, 'RG259':14,\n",
    "                                                              'RG281':15, 'RG258':16, 'RG266':17, 'RG260':18, 'RG274':19, 'RG256':20, 'RG275':21,\n",
    "                                                              'RG273':22, 'RG267':23, 'RG272':24, 'RG251':25, 'RG262':26, 'RG264':27, 'RG278':28,\n",
    "                                                              'RG276':29, 'RG263':30, 'RG250':31, 'RG255':32, 'RG253':33, 'RG271':34})\n",
    "train['Channel_Code']=train['Channel_Code'].replace({'X3':2,'X1':0,'X2':1,'X4':3})\n",
    "train['Credit_Product']=train['Credit_Product'].replace({'No':0,'Yes':1, 'Unknown':2})\n",
    "train['Is_Active']=train['Is_Active'].replace({'No':0,'Yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Gender']=test['Gender'].replace({'Male':1,'Female':0})\n",
    "test['Occupation']=test['Occupation'].replace({'Other':0,'Salaried':1,'Self_Employed':2, 'Entrepreneur':3})\n",
    "test['Occupation']=test['Occupation'].astype(int)\n",
    "test['Region_Code']=test['Region_Code'].replace({'RG268':0,'RG277':1,'RG270':2,'RG282':3,'RG261':4, 'RG265':5, 'RG283':6, 'RG254':7,\n",
    "                                                              'RG269':8, 'RG257':9, 'RG279':10, 'RG280':11, 'RG252':12, 'RG284':13, 'RG259':14,\n",
    "                                                              'RG281':15, 'RG258':16, 'RG266':17, 'RG260':18, 'RG274':19, 'RG256':20, 'RG275':21,\n",
    "                                                              'RG273':22, 'RG267':23, 'RG272':24, 'RG251':25, 'RG262':26, 'RG264':27, 'RG278':28,\n",
    "                                                              'RG276':29, 'RG263':30, 'RG250':31, 'RG255':32, 'RG253':33, 'RG271':34})\n",
    "test['Channel_Code']=test['Channel_Code'].replace({'X3':2,'X1':0,'X2':1,'X4':3})\n",
    "test['Credit_Product']=test['Credit_Product'].replace({'No':0,'Yes':1, 'Unknown':2})\n",
    "test['Is_Active']=test['Is_Active'].replace({'No':0,'Yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create list of categorical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['Gender', 'Age', 'Region_Code', 'Occupation', 'Channel_Code', 'Vintage', 'Credit_Product', 'Avg_Account_Balance', 'Is_Active']\n",
    "cat_col=['Gender','Region_Code', 'Occupation', 'Channel_Code', 'Credit_Product', 'Is_Active' ]"
   ]
  },
  {
   "source": [
    "### Create test train data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('Is_Lead', axis=1)\n",
    "y = train[['Is_Lead']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=150303,stratify=y,shuffle=True)"
   ]
  },
  {
   "source": [
    "# Model Building, Training and Optimization "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Initialize catboost classifier "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catb = CatBoostClassifier()\n",
    "catb= catb.fit(X_train, y_train,cat_features=cat_col,eval_set=(X_test, y_test),early_stopping_rounds=30,verbose=100)\n",
    "y_pred = catb.predict(X_test)\n",
    "proba = catb.predict_proba(X_test)[:, 1]\n",
    "print('CatBoost Base Accuracy : {}'.format(accuracy_score(y_test,y_pred)))\n",
    "print('CatBoost Base ROC_AUC_SCORE: {}'.format(roc_auc_score(y_test,proba)))"
   ]
  },
  {
   "source": [
    "### Initialize base LGBM classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "proba = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model metrics \n",
    "print('LGBM Base Accuracy : {}'.format(accuracy_score(y_test,y_pred)))\n",
    "print('LGBM Base ROC_AUC_SCORE: {}'.format(roc_auc_score(y_test,proba)))"
   ]
  },
  {
   "source": [
    "### Tune Model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 30)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 1, 500)\n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0.0000001, 1)\n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 2, 5000)\n",
    "    min_child_samples = trial.suggest_int('min_child_samples', 3, 200)\n",
    "    reg_alpha = trial.suggest_int(\"reg_alpha\", 1, 10)\n",
    "    reg_lambda = trial.suggest_int(\"reg_lambda\", 1, 10)\n",
    "    model = LGBMClassifier(\n",
    "        learning_rate=learning_rate, \n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth,\n",
    "        num_leaves=num_leaves, \n",
    "        min_child_samples=min_child_samples,\n",
    "        random_state=0\n",
    "    )\n",
    "    return model\n",
    "\n",
    "sampler = TPESampler(seed=0)\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_train, y_train)\n",
    "    proba = model.predict_proba(X_test)[:,1]\n",
    "    score = roc_auc_score(y_test,proba)\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "lgb_params = study.best_params\n",
    "lgb_params['random_state'] = 0\n",
    "lgb = LGBMClassifier(**lgb_params)\n",
    "lgb.fit(X_train, y_train)\n",
    "proba = lgb.predict_proba(X_test)[:,1]\n",
    "print('Optimized LightGBM roc_auc_score', roc_auc_score(y_test, proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb"
   ]
  },
  {
   "source": [
    "### Fit Tuned model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM = lgb\n",
    "LGBM.fit(X, y)\n",
    "y_pred = LGBM.predict(X_test)\n",
    "proba = LGBM.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LGBM Tuned Accuracy : {}'.format(accuracy_score(y_test,y_pred)))\n",
    "print('LGBM Tuned ROC_AUC_SCORE: {}'.format(roc_auc_score(y_test,proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['Is_Lead'], axis=1)"
   ]
  },
  {
   "source": [
    "### Stacking the models "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_proba = LGBM.predict_proba(test)[:, 1] # Class 1 probability of LGBM model\n",
    "cat_proba = catb.predict_proba(test)[:, 1] # Class 1 probability of CatBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = ((LGBM_proba * 0.45) + (cat_proba * 0.55))/2\n",
    "sample_sub['Is_Lead'] = submit_proba"
   ]
  },
  {
   "source": [
    "## Prepare submission "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##sample_sub.to_csv('sixth_submission.csv', index=False) "
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}